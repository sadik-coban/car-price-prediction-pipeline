import re
import pandas as pd
from bs4 import BeautifulSoup
from datetime import datetime
from sqlalchemy import create_engine
from dotenv import load_dotenv
import os

df = pd.read_json("data\\audi\\2026-01-27_02-10\\details.jsonl", lines=True)
df = df[df["Fiyat"].notna()].copy()
df = df[df["Fiyat"] != ""].copy()


# data\bmw\2026-01-18_19-56\details.jsonl
# data\audi\2026-01-18_19-56\details.jsonl

# data\bmw\2026-01-27_02-10\details.jsonl
# data\audi\2026-01-27_02-10\details.jsonl


def parse_turkish_date(date_str):
    """
    '26 KasÄ±m 2025' formatÄ±ndaki metni '2025-11-26' (datetime.date) formatÄ±na Ã§evirir.
    """
    if not date_str or pd.isna(date_str):
        return None

    # Gereksiz boÅŸluklarÄ± temizle
    date_str = str(date_str).strip()

    tr_months = {
        "Ocak": "01",
        "Åubat": "02",
        "Mart": "03",
        "Nisan": "04",
        "MayÄ±s": "05",
        "Haziran": "06",
        "Temmuz": "07",
        "AÄŸustos": "08",
        "EylÃ¼l": "09",
        "Ekim": "10",
        "KasÄ±m": "11",
        "AralÄ±k": "12",
    }

    try:
        # Ã–rn: "26 KasÄ±m 2025" -> ["26", "KasÄ±m", "2025"]
        parts = date_str.split()
        if len(parts) == 3:
            day, month_txt, year = parts
            month_num = tr_months.get(month_txt)
            if month_num:
                # YYYY-MM-DD formatÄ±nda string veya datetime objesi dÃ¶ndÃ¼r
                return datetime.strptime(f"{year}-{month_num}-{day}", "%Y-%m-%d").date()
    except:
        return None
    return None


def process_to_silver_full(raw_item):
    """
    TÃ¼m kolonlarÄ± kapsayan, prefixli ve teknik 4'lÃ¼ yapÄ±ya sahip Silver iÅŸlemci.
    """

    # --- YARDIMCI ARAÃ‡LAR ---
    def clean_num(val):
        if val is None or pd.isna(val):
            return None
        # SayÄ± dÄ±ÅŸÄ±ndaki her ÅŸeyi at (nokta ve virgÃ¼l hariÃ§)
        # 1.620 -> 1620 | 11,8 -> 11.8
        cleaned = re.sub(r"[^\d,]", "", str(val)).replace(",", ".")
        return float(cleaned) if cleaned else None

    def get_interval_stats(val):
        """Low, Up, Val (Mean), Is_Range dÃ¶ner."""
        if not val or pd.isna(val):
            return None, None, None, False
        nums = re.findall(r"(\d+)", str(val).replace(".", ""))
        if not nums:
            return None, None, None, False
        nums = [float(n) for n in nums]
        if len(nums) >= 2:
            low, up = min(nums), max(nums)
            return low, up, (low + up) / 2, True
        else:
            v = nums[0]
            return v, v, v, False

    def analyze_damage_locations(damage_list):
        """Hasar listesini parÃ§alara ve durumlara (Degisen/Boyali/Lokal) bÃ¶ler."""
        text = str(damage_list).lower()
        parts_map = {
            "tavan": "tavan",
            "kaput": "kaput",
            "bagaj": "bagaj",
            "door_fl": "sol Ã¶n kapÄ±",
            "door_fr": "saÄŸ Ã¶n kapÄ±",
            "door_rl": "sol arka kapÄ±",
            "door_rr": "saÄŸ arka kapÄ±",
            "fender_fl": "sol Ã¶n Ã§amurluk",
            "fender_fr": "saÄŸ Ã¶n Ã§amurluk",
            "fender_rl": "sol arka Ã§amurluk",
            "fender_rr": "saÄŸ arka Ã§amurluk",
        }
        damage_results = {}
        for key, tr_name in parts_map.items():
            # DeÄŸiÅŸen (1), Lokal (1), BoyalÄ± (1) - Bilgi kaybÄ± olmamasÄ± iÃ§in her durum ayrÄ± kolon
            deg = (
                1
                if f"{tr_name}: deÄŸiÅŸen" in text or f"{tr_name}: deÄŸiÅŸmiÅŸ" in text
                else 0
            )
            lok = 1 if f"{tr_name}: lokal" in text and deg == 0 else 0
            boy = 1 if f"{tr_name}: boyalÄ±" in text and deg == 0 and lok == 0 else 0

            damage_results[f"{key}_degisen"] = deg
            damage_results[f"{key}_boyali"] = boy
            damage_results[f"{key}_lokal"] = lok
        return damage_results

    # 1. TEMEL METADATA
    # Ä°lan Tarihi DÃ¶nÃ¼ÅŸÃ¼mÃ¼
    # JSON'da key genellikle "KÄ±saBilgi - Ä°lan Tarihi" olarak gelir, verini kontrol et.
    listing_date = parse_turkish_date(raw_item.get("KÄ±saBilgi - Ä°lan Tarihi"))
    ad_id_raw = raw_item.get("KÄ±saBilgi - Ä°lan No", "")
    ad_id = (
        int(re.search(r"(\d+)", ad_id_raw).group(1))
        if re.search(r"(\d+)", ad_id_raw)
        else None
    )

    # Saat yuvarlama (Dakika/Saniye -> 00)
    scraped_at = pd.to_datetime(raw_item.get("scraped_at"))

    # search_date (Ã–rn: 2026-01-18_01-05) -> SQL Timestamp formatÄ±na
    search_raw = str(raw_item.get("search_date", ""))
    try:
        # Alt tireli formatÄ± standart zaman formatÄ±na Ã§eviriyoruz
        search_ts = datetime.strptime(search_raw, "%Y-%m-%d_%H-%M")
    except:
        search_ts = None

    # AÃ§Ä±klama TemizliÄŸi
    desc_html = raw_item.get("Aciklama_HTML", "")
    desc_text = (
        BeautifulSoup(desc_html, "html.parser").get_text(" ", strip=True).lower()
        if desc_html
        else ""
    )

    # CC ve HP iÃ§in 4'lÃ¼ YapÄ±
    cc_low, cc_up, cc_val, cc_is_range = get_interval_stats(
        raw_item.get("KÄ±saBilgi - Motor Hacmi")
    )
    hp_low, hp_up, hp_val, hp_is_range = get_interval_stats(
        raw_item.get("KÄ±saBilgi - Motor GÃ¼cÃ¼")
    )

    # DetaylÄ± Hasar Analizi
    loc_damage = analyze_damage_locations(raw_item.get("Hasar_Listesi", []))

    # 2. SILVER SÃ–ZLÃœÄÃœ OLUÅTURMA
    silver_data = {
        # Kimlik ve BaÅŸlÄ±k
        "ad_id": ad_id,
        "listing_date": listing_date,
        "ad_title": raw_item.get("Ilan_Basligi"),
        # "ilan tarihini buraya ekle"
        "brand": raw_item.get("brand"),
        "series": raw_item.get("KÄ±saBilgi - Seri"),
        "model": raw_item.get("KÄ±saBilgi - Model"),
        "location": raw_item.get("Konum"),
        "price": clean_num(raw_item.get("Fiyat")),
        # --- KISA BÄ°LGÄ° (kb_) KOLONLARI ---
        "kb_year": int(raw_item.get("KÄ±saBilgi - YÄ±l", 0)),
        "kb_mileage": clean_num(raw_item.get("KÄ±saBilgi - Kilometre")),
        "kb_transmission": raw_item.get("KÄ±saBilgi - Vites Tipi"),
        "kb_fuel": raw_item.get("KÄ±saBilgi - YakÄ±t Tipi"),
        "kb_body_type": raw_item.get("KÄ±saBilgi - Kasa Tipi"),
        "kb_color": raw_item.get("KÄ±saBilgi - Renk"),
        "kb_drivetrain": raw_item.get("KÄ±saBilgi - Ã‡ekiÅŸ"),
        "kb_condition": raw_item.get("KÄ±saBilgi - AraÃ§ Durumu"),
        "kb_is_heavy_damaged": raw_item.get("KÄ±saBilgi - AÄŸÄ±r HasarlÄ±") == "Evet",
        "kb_trade_available": raw_item.get("KÄ±saBilgi - Takasa Uygun")
        == "Takasa Uygun",
        "kb_seller_type": raw_item.get("KÄ±saBilgi - Kimden"),
        "kb_fuel_cons_avg": clean_num(raw_item.get("KÄ±saBilgi - Ort. YakÄ±t TÃ¼ketimi")),
        "kb_fuel_tank": clean_num(raw_item.get("KÄ±saBilgi - YakÄ±t Deposu")),
        # --- GENEL BAKIÅ (gb_) KOLONLARI ---
        "gb_year": int(raw_item.get("Genel BakÄ±ÅŸ - YÄ±l", 0)),
        "gb_mileage": clean_num(raw_item.get("Genel BakÄ±ÅŸ - Kilometre")),
        "gb_fuel": raw_item.get("Genel BakÄ±ÅŸ - YakÄ±t Tipi"),
        "gb_transmission": raw_item.get("Genel BakÄ±ÅŸ - Vites Tipi"),
        "gb_color": raw_item.get("Genel BakÄ±ÅŸ - Renk"),
        "gb_warranty_status": raw_item.get("Genel BakÄ±ÅŸ - Garanti Durumu"),
        "gb_usage_type": raw_item.get("Genel BakÄ±ÅŸ - AraÃ§ TÃ¼rÃ¼"),
        "gb_is_first_owner": "Ä°lk Sahibi"
        in str(raw_item.get("Genel BakÄ±ÅŸ - AracÄ±n ilk sahibiyim")),
        "gb_segment": raw_item.get("Genel BakÄ±ÅŸ - SÄ±nÄ±fÄ±"),
        "gb_body_type": raw_item.get("Genel BakÄ±ÅŸ - Kasa Tipi"),
        "gb_mtv_yearly": clean_num(raw_item.get("Genel BakÄ±ÅŸ - YÄ±llÄ±k MTV")),
        # --- TEKNÄ°K Ã–ZELLÄ°KLER (4'lÃ¼ YapÄ± ve Tekiller) ---
        "engine_cc_low": cc_low,
        "engine_cc_up": cc_up,
        "engine_cc_val": cc_val,
        "engine_cc_is_range": cc_is_range,
        "power_hp_low": hp_low,
        "power_hp_up": hp_up,
        "power_hp_val": hp_val,
        "power_hp_is_range": hp_is_range,
        "torque_nm": clean_num(raw_item.get("Motor ve Performans - Tork")),
        "cylinder_count": clean_num(
            raw_item.get("Motor ve Performans - Silindir SayÄ±sÄ±")
        ),
        "max_speed_kmh": clean_num(raw_item.get("Motor ve Performans - Maksimum HÄ±z")),
        "accel_0_100": clean_num(
            raw_item.get("Motor ve Performans - HÄ±zlanma (0-100)")
        ),
        # YakÄ±t DetaylarÄ±
        "city_fuel_cons": clean_num(
            raw_item.get("YakÄ±t TÃ¼ketimi - Åehir Ä°Ã§i YakÄ±t TÃ¼ketimi")
        ),
        "highway_fuel_cons": clean_num(
            raw_item.get("YakÄ±t TÃ¼ketimi - Åehir DÄ±ÅŸÄ± YakÄ±t TÃ¼ketimi")
        ),
        # Boyut ve Kapasite
        "length_mm": clean_num(raw_item.get("Boyut ve Kapasite - Uzunluk")),
        "width_mm": clean_num(raw_item.get("Boyut ve Kapasite - GeniÅŸlik")),
        "height_mm": clean_num(raw_item.get("Boyut ve Kapasite - YÃ¼kseklik")),
        "weight_kg": clean_num(raw_item.get("Boyut ve Kapasite - AÄŸÄ±rlÄ±k")),
        "curb_weight_kg": clean_num(raw_item.get("Boyut ve Kapasite - BoÅŸ AÄŸÄ±rlÄ±ÄŸÄ±")),
        "trunk_capacity_lt": clean_num(raw_item.get("Boyut ve Kapasite - Bagaj Hacmi")),
        "wheelbase_mm": clean_num(raw_item.get("Boyut ve Kapasite - Aks AralÄ±ÄŸÄ±")),
        # Hasar Durumu
        "is_heavy_damaged": bool(raw_item.get("Agir_Hasar", False)),
        "tramer_fee": raw_item.get("Tramer_Tutari", 0),
        "count_changed": raw_item.get("Degisen_Parca_Sayisi", 0),
        "count_painted": raw_item.get("Boyali_Parca_Sayisi", 0),
        "count_local_painted": raw_item.get("Lokal_Boyali_Parca_Sayisi", 0),
        **loc_damage,
        # Zamanlama ve AÃ§Ä±klama
        "description_text": desc_text,
        "scraped_at": scraped_at,
        "search_date": search_ts,
    }
    print(silver_data["ad_id"])
    return silver_data


silver_df = df.apply(
    lambda row: pd.Series(process_to_silver_full(row.to_dict())), axis=1
)


print(silver_df.head())

print(silver_df["kb_mileage"], silver_df["gb_mileage"], silver_df["engine_cc_val"])

load_dotenv()

connection_string = os.getenv("DATABASE_URL")

engine = create_engine(connection_string)

# 1. VeritabanÄ±ndaki mevcut ID'leri Ã§ek
existing_ids = pd.read_sql("SELECT ad_id FROM test.car_listings", engine)[
    "ad_id"
].tolist()

# 2. df iÃ§inden veritabanÄ±nda OLMAYANLARI filtrele
new_df = silver_df[~silver_df["ad_id"].isin(existing_ids)]

# 3. Sadece yenileri gÃ¶nder
if not new_df.empty:
    new_df.to_sql(
        name="car_listings",
        con=engine,
        schema="test",
        if_exists="append",
        index=False,
        chunksize=500,
    )
    print(f"ğŸš€ {len(new_df)} yeni ilan eklendi.")
else:
    print("âœ¨ TÃ¼m ilanlar zaten gÃ¼ncel, yeni veri yok.")
